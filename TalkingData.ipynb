{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import tarfile\n",
    "import zipfile\n",
    "#import StringIO\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from scipy import ndimage\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import linear_model, decomposition, datasets, ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer,precision_score, recall_score, f1_score, average_precision_score, accuracy_score\n",
    "\n",
    "\n",
    "datadir=\"./data/TalkingData/\"\n",
    "\n",
    "# Config the matlotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some function def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadData(datadir,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    #data = pd.read_csv(filename)\n",
    "    data = ''\n",
    "    print (\"loading: \"+datadir+filename)\n",
    "    try:\n",
    "        if zipfile.is_zipfile(datadir+filename):\n",
    "            z = zipfile.ZipFile(datadir+filename)\n",
    "            filename = z.open(filename[:-4])\n",
    "        else:\n",
    "            filename=datadir+filename\n",
    "        data = pd.read_csv(filename, parse_dates=True)  \n",
    "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
    "        print(e)\n",
    "    return data\n",
    "\n",
    "def writeData(data,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    try:\n",
    "        data.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be written.\")\n",
    "        print(e)\n",
    "    verify=[]\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                verify.append(line)\n",
    "        f.closed\n",
    "        return verify[:5]\n",
    "    except IOError:\n",
    "        sys.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "   \n",
    "def runPredict(clf,data, display=True):\n",
    "    index=random.randrange(len(data))\n",
    "    y_pred = clf.predict(data[index].reshape(1, -1))[0]\n",
    "    if display==True:\n",
    "        print \"for:\",data[index], \"prediction:\",y_pred\n",
    "    return y_pred\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "    #print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "    \n",
    "# Predict on training set and compute F1 score\n",
    "def predict_labels(clf, features, target):\n",
    "    #print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    #print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    return f1_score(target, y_pred,average='micro'),end - start #(None, 'micro', 'macro', 'weighted', 'samples')\n",
    "\n",
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    timeTrain=train_classifier(clf, X_train, y_train)\n",
    "    predict_train,trainDelta=predict_labels(clf, X_train, y_train)\n",
    "    predict_test,testDelta=predict_labels(clf, X_test, y_test)\n",
    "    return predict_test,testDelta,predict_train,trainDelta,timeTrain # let's return the scores, so we can use them for comparisons\n",
    "\n",
    "#for each data set size run and plot a train/test\n",
    "def runTests(test_sizes, train_dataset,train_labels,test_dataset,test_labels, clf=\"\", usePCA=False):\n",
    "    test_f1=[]\n",
    "    train_f1=[]\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        # Set up the train set for the test size\n",
    "        X_train=train_dataset[:test_size]\n",
    "        y_train=train_labels[:test_size]\n",
    "        # Same for test\n",
    "        X_test=test_dataset[-test_size:]\n",
    "        y_test=test_labels[-test_size:]\n",
    "\n",
    " \n",
    "        if clf == \"\":\n",
    "            clf=LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42,  max_iter=1000,C=1e-5)\n",
    "            \n",
    "        if usePCA ==True:\n",
    "            pca=decomposition.PCA(n_components = 14*14)\n",
    "            clf=Pipeline(steps=[('pca', pca), ('classifier', clf )]) # set up the clf as a pipeline ])\n",
    "        # Fit model to training data\n",
    "        test,testDelta,train,trainDelta,timeTrain = train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "        test_f1.append(test)\n",
    "        train_f1.append(train)\n",
    "        print (\"------------------------------------------\")\n",
    "        print (\"Training set size: {},\".format(len(X_train)),\"Train time (secs): {:.3f}\".format(timeTrain))\n",
    "        print (\"F1 score for training set: {},\".format(train),\"Prediction time (secs): {:.3f}\".format(trainDelta))\n",
    "        print (\"F1 score for test set: {},\".format(test),\"Prediction time (secs): {:.3f}\".format(testDelta))\n",
    "\n",
    "    \n",
    "    print (\"\\n\",clf)\n",
    "    print(\"Test F1:{}\".format(test_f1))\n",
    "    display(\"Train F1:{}\".format(train_f1))\n",
    "    plt.plot(test_f1,label=\"Test F1\")\n",
    "    plt.plot(train_f1,label=\"Train F1\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.title(\"F1 Score per run\")\n",
    "    plt.show()\n",
    "    \n",
    "    return clf    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./data/TalkingData/app_events.csv.zip\n",
      "Dataset has 32473067 samples with 4 features each.\n",
      "loading: ./data/TalkingData/app_labels.csv.zip\n",
      "Dataset has 459943 samples with 2 features each.\n",
      "loading: ./data/TalkingData/events.csv.zip\n",
      "Dataset has 3252950 samples with 5 features each.\n",
      "loading: ./data/TalkingData/label_categories.csv.zip\n",
      "Dataset has 930 samples with 2 features each.\n",
      "loading: ./data/TalkingData/phone_brand_device_model.csv.zip\n",
      "Dataset has 187245 samples with 3 features each.\n",
      "loading: ./data/TalkingData/gender_age_train.csv.zip\n",
      "Dataset has 74645 samples with 4 features each.\n"
     ]
    }
   ],
   "source": [
    "# load up the data!\n",
    "app_events = loadData(datadir,'app_events.csv.zip')\n",
    "app_labels = loadData(datadir,'app_labels.csv.zip')\n",
    "events = loadData(datadir,'events.csv.zip')\n",
    "label_categories = loadData(datadir,'label_categories.csv.zip')\n",
    "\n",
    "phone_brand_device_model = loadData(datadir,'phone_brand_device_model.csv.zip')\n",
    "phone_brand_device_model.drop_duplicates('device_id',keep='first', inplace=True)\n",
    "\n",
    "gender_age_train = loadData(datadir,'gender_age_train.csv.zip')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7324884708820027918</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4494216993218550286</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8694625920731541625</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id  label_id\n",
       "0  7324884708820027918       251\n",
       "1 -4494216993218550286       251\n",
       "2  6058196446775239644       406\n",
       "3  6058196446775239644       407\n",
       "4  8694625920731541625       406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>game-game type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>game-Game themes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>game-Art Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>game-Leisure time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_id           category\n",
       "0         1                NaN\n",
       "1         2     game-game type\n",
       "2         3   game-Game themes\n",
       "3         4     game-Art Style\n",
       "4         5  game-Leisure time"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('size of app_labels:', 459943)\n",
      "(0, app_id      7324884708820027918\n",
      "label_id                    251\n",
      "Name: 0, dtype: int64)\n",
      "(10000, app_id      3651079935107643964\n",
      "label_id                    713\n",
      "Name: 10000, dtype: int64)\n",
      "(20000, app_id      1483321555693163019\n",
      "label_id                    717\n",
      "Name: 20000, dtype: int64)\n",
      "(30000, app_id      739987247270796251\n",
      "label_id                   711\n",
      "Name: 30000, dtype: int64)\n",
      "(40000, app_id      3481474984493300197\n",
      "label_id                    711\n",
      "Name: 40000, dtype: int64)\n",
      "(50000, app_id     -7270685603947800676\n",
      "label_id                    718\n",
      "Name: 50000, dtype: int64)\n",
      "(60000, app_id      2748071763173703515\n",
      "label_id                    711\n",
      "Name: 60000, dtype: int64)\n",
      "(70000, app_id      7550692134104585959\n",
      "label_id                    704\n",
      "Name: 70000, dtype: int64)\n",
      "(80000, app_id     -6541810269037825584\n",
      "label_id                    704\n",
      "Name: 80000, dtype: int64)\n",
      "(90000, app_id     -6761151265103874404\n",
      "label_id                    704\n",
      "Name: 90000, dtype: int64)\n",
      "(100000, app_id     -5418639328840716979\n",
      "label_id                    704\n",
      "Name: 100000, dtype: int64)\n",
      "(110000, app_id     -2209654259077283886\n",
      "label_id                    548\n",
      "Name: 110000, dtype: int64)\n",
      "(120000, app_id     -4548801791786859478\n",
      "label_id                    548\n",
      "Name: 120000, dtype: int64)\n",
      "(130000, app_id      4645631278278088100\n",
      "label_id                    548\n",
      "Name: 130000, dtype: int64)\n",
      "(140000, app_id      5284717646024120559\n",
      "label_id                    761\n",
      "Name: 140000, dtype: int64)\n",
      "(150000, app_id      7560624707698259642\n",
      "label_id                    782\n",
      "Name: 150000, dtype: int64)\n",
      "(160000, app_id     -8583878696729198708\n",
      "label_id                    704\n",
      "Name: 160000, dtype: int64)\n",
      "(170000, app_id     -2917536355868705176\n",
      "label_id                    704\n",
      "Name: 170000, dtype: int64)\n",
      "(180000, app_id      1832617969218122536\n",
      "label_id                    548\n",
      "Name: 180000, dtype: int64)\n",
      "(190000, app_id      6838111464157500574\n",
      "label_id                    548\n",
      "Name: 190000, dtype: int64)\n",
      "(200000, app_id      2232580722076596355\n",
      "label_id                    820\n",
      "Name: 200000, dtype: int64)\n",
      "(210000, app_id     -3957094102598794106\n",
      "label_id                    798\n",
      "Name: 210000, dtype: int64)\n",
      "(220000, app_id     -1729975920402764325\n",
      "label_id                    796\n",
      "Name: 220000, dtype: int64)\n",
      "(230000, app_id     -642644277109215647\n",
      "label_id                   811\n",
      "Name: 230000, dtype: int64)\n",
      "(240000, app_id     -8554266412360250261\n",
      "label_id                    810\n",
      "Name: 240000, dtype: int64)\n",
      "(250000, app_id      8684542685591454407\n",
      "label_id                    795\n",
      "Name: 250000, dtype: int64)\n",
      "(260000, app_id      898684280583627524\n",
      "label_id                   795\n",
      "Name: 260000, dtype: int64)\n",
      "(270000, app_id      448305848962741113\n",
      "label_id                   795\n",
      "Name: 270000, dtype: int64)\n",
      "(280000, app_id      6256304266206928393\n",
      "label_id                    795\n",
      "Name: 280000, dtype: int64)\n",
      "(290000, app_id      9112462997408434928\n",
      "label_id                    795\n",
      "Name: 290000, dtype: int64)\n",
      "(300000, app_id     -2126931328613278753\n",
      "label_id                    794\n",
      "Name: 300000, dtype: int64)\n",
      "(310000, app_id     -1465161111736094647\n",
      "label_id                    794\n",
      "Name: 310000, dtype: int64)\n",
      "(320000, app_id     -7878172399535308579\n",
      "label_id                    794\n",
      "Name: 320000, dtype: int64)\n",
      "(330000, app_id      3848615968874010336\n",
      "label_id                    794\n",
      "Name: 330000, dtype: int64)\n",
      "(340000, app_id     -2133481719424997587\n",
      "label_id                    405\n",
      "Name: 340000, dtype: int64)\n",
      "(350000, app_id     -234278193874400211\n",
      "label_id                   405\n",
      "Name: 350000, dtype: int64)\n",
      "(360000, app_id     -6710683876964731311\n",
      "label_id                    405\n",
      "Name: 360000, dtype: int64)\n",
      "(370000, app_id     -2521878403960602350\n",
      "label_id                    405\n",
      "Name: 370000, dtype: int64)\n",
      "(380000, app_id     -6333072568214120477\n",
      "label_id                    405\n",
      "Name: 380000, dtype: int64)\n",
      "(390000, app_id      5172968826472836789\n",
      "label_id                    795\n",
      "Name: 390000, dtype: int64)\n",
      "(400000, app_id     -3753052268851403761\n",
      "label_id                    870\n",
      "Name: 400000, dtype: int64)\n",
      "(410000, app_id      6755436778478318451\n",
      "label_id                    854\n",
      "Name: 410000, dtype: int64)\n",
      "(420000, app_id     -2124845483491445764\n",
      "label_id                     14\n",
      "Name: 420000, dtype: int64)\n",
      "(430000, app_id      7326901220459373568\n",
      "label_id                    168\n",
      "Name: 430000, dtype: int64)\n",
      "(440000, app_id     -4382068773988816135\n",
      "label_id                    134\n",
      "Name: 440000, dtype: int64)\n",
      "(450000, app_id      6983979008576903344\n",
      "label_id                    548\n",
      "Name: 450000, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7324884708820027918</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4494216993218550286</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8694625920731541625</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id  label_id\n",
       "0  7324884708820027918       251\n",
       "1 -4494216993218550286       251\n",
       "2  6058196446775239644       406\n",
       "3  6058196446775239644       407\n",
       "4  8694625920731541625       406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(app_labels.head(5))\n",
    "display(label_categories.head(5))\n",
    "print (\"size of app_labels:\",len(app_labels))\n",
    "\n",
    "for i in range(len(app_labels)):\n",
    "    app_labels.loc[i]['category']= \"TEST\"\n",
    "    if i%10000 == 0:\n",
    "        print(i,app_labels.loc[i])\n",
    "\n",
    "display(app_labels.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# the ONE TABLE to rule them all\n",
    "\n",
    "print (\"merging: events\")\n",
    "df = gender_age_train.merge(events, how='left', on='device_id')\n",
    "print (\"merging: phone_brand_device_model\")\n",
    "df = df.merge(phone_brand_device_model, how='left', on='device_id')\n",
    "\n",
    "print (\"merging: phone_brand_device_model\")\n",
    "df = df.merge(app_events, how='left', on='event_id')\n",
    "\n",
    "print (\"merging: app_labels\")\n",
    "df = df.merge(app_labels, how='left', on='app_id')\n",
    "print (\"merging: label_categories\")\n",
    "df=  df.merge(label_categories, how='left', on='label_id')\n",
    "\n",
    "\n",
    "#df=df.fillna(0)\n",
    "\n",
    "#brandLE = LabelEncoder().fit(df.phone_brand)\n",
    "#df['phone_brand'] = brandLE.transform(df['phone_brand'])\n",
    "#modelLE = LabelEncoder().fit(df.device_model)\n",
    "#df['device_model'] = modelLE.transform(df['device_model'])\n",
    "#groupLE = LabelEncoder().fit(df.group)\n",
    "#df['group'] = groupLE.transform(df['group'])\n",
    "#categoryLE = LabelEncoder().fit(df.category)\n",
    "#df['category'] = categoryLE.transform(df['category'])\n",
    "#app_idLE = LabelEncoder().fit(df.app_id)\n",
    "#df['app_id'] = app_idLE.transform(df['app_id'])\n",
    "\n",
    "df.info()\n",
    "display (df.head(5))\n",
    "df=df.drop(['gender','age', 'event_id', 'label_id','is_installed','is_active', 'event_id', 'timestamp','device_id', 'longitude','latitude' ],1)\n",
    "display(df.info())\n",
    "display(df.head(5))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_app_id=df.loc[3].app_id\n",
    "\n",
    "print(df[df.app_id==curr_app_id].head(10))\n",
    "print(app_labels[app_labels.app_id==curr_app_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_idLE.inverse_transform(6854)\n",
    "display(app_idLE.inverse_transform(3514))\n",
    "\n",
    "display(app_labels[app_labels['app_id']==app_idLE.inverse_transform(3514)])\n",
    "\n",
    "categoryLE.inverse_transform(713)\n",
    "categoryLE.inverse_transform(704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display (df.head(2))\n",
    "\n",
    "counterCat=0\n",
    "counterApp=0\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i].category!=0:\n",
    "        counterCat+=1\n",
    "    if df.loc[i].app_id!=0:\n",
    "        counterApp+=1\n",
    "        \n",
    "    if i % 100000 ==0:\n",
    "        print (i, \"category:\",df.loc[i].category, counterCat,\"App:\",df.loc[i].app_id, counterApp)\n",
    "print(\"counter:\",counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data intro train/test, train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=df.drop('group',1)\n",
    "y=df['group']\n",
    "\n",
    "display(x.head(2))\n",
    "display(y.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  train/validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "dataSize=X_train.shape[0]\n",
    "print (\"size of train data\",dataSize, )\n",
    "test_sizes=[50]\n",
    "for i in range(5):\n",
    "    test_sizes.append(int(round(dataSize*(i+1)*.2)))\n",
    "\n",
    "#test_sizes=[63,630,6300,31500]\n",
    "#test_sizes=[50,500,5001]\n",
    "print (\"run tests of size\",test_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display (X_train[0], y_train[0])\n",
    "display (x[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Logistic:\")\n",
    "clf=runTests(test_sizes, X_train,y_train,X_test,y_test)\n",
    "print(\"Validation Prediction is:\",runPredict(clf,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"AdaBoost:\")\n",
    "clf = runTests(test_sizes, X_train,y_train,X_test,y_test,ensemble.AdaBoostClassifier())\n",
    "print(\"Validation Prediction is:\",runPredict(clf,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Validation Prediction is:\",runPredict(clf,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
