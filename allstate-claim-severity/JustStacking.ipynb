{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv.zip\n",
      "train.csv.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,sys,time,random,math,time\n",
    "import tarfile, zipfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "\n",
    "from sklearn import decomposition, datasets, ensemble\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer,precision_score, recall_score, f1_score, average_precision_score, accuracy_score, mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "datadir=\"./input/\"\n",
    "print(check_output([\"ls\", datadir]).decode(\"utf8\"))\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(datadir,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    #data = pd.read_csv(filename)\n",
    "    data = ''\n",
    "    print (\"loading: \"+datadir+filename)\n",
    "    try:\n",
    "        if zipfile.is_zipfile(datadir+filename):\n",
    "            z = zipfile.ZipFile(datadir+filename)\n",
    "            filename = z.open(filename[:-4])\n",
    "        else:\n",
    "            filename=datadir+filename\n",
    "        data = pd.read_csv(filename, parse_dates=True)  \n",
    "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
    "        print(e)\n",
    "    return data\n",
    "\n",
    "def writeData(data,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    try:\n",
    "        data.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be written.\")\n",
    "        print(e)\n",
    "    verify=[]\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                verify.append(line)\n",
    "        f.closed\n",
    "        return verify[:5]\n",
    "    except IOError:\n",
    "        sys.std\n",
    "        \n",
    "def LabelEncoder(data):\n",
    "    # lifted in parts from:\n",
    "    #https://www.kaggle.com/mmueller/allstate-claims-severity/yet-another-xgb-starter/code\n",
    "    features = data.columns\n",
    "    cats = [feat for feat in features if 'cat' in feat]\n",
    "    for feat in cats:\n",
    "        data[feat] = pd.factorize(data[feat], sort=True)[0]\n",
    "    return data\n",
    "\n",
    "# XGB!\n",
    "\n",
    "def xgbfit(X_train,y_train):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "\n",
    "    xgb_params = {\n",
    "        'seed': 0,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.075,\n",
    "        'objective': 'reg:linear',\n",
    "        'max_depth': 6,\n",
    "        'num_parallel_tree': 1,\n",
    "        'min_child_weight': 1,\n",
    "        'eval_metric': 'mae',\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "    res = xgb.cv(xgb_params, dtrain, num_boost_round=750, nfold=4, seed=42, stratified=False,\n",
    "                 early_stopping_rounds=15, verbose_eval=100, show_stdv=True, maximize=False)\n",
    "    print(\"fit time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "    best_nrounds = res.shape[0] - 1\n",
    "    cv_mean = res.iloc[-1, 0]\n",
    "    cv_std = res.iloc[-1, 1]\n",
    "    print('CV-Mean: {0}+{1}'.format(cv_mean, cv_std))\n",
    "    # XGB Train!\n",
    "    start_time = time.time()\n",
    "    gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "    print(\"Train time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    return gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/train.csv.zip\n",
      "Dataset has 188318 samples with 132 features each.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188318 entries, 0 to 188317\n",
      "Columns: 132 entries, id to loss\n",
      "dtypes: float64(15), int64(1), object(116)\n",
      "memory usage: 189.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B   ...     0.718367   \n",
       "1   2    A    B    A    A    A    A    A    A    B   ...     0.438917   \n",
       "2   5    A    B    A    A    B    A    A    A    B   ...     0.289648   \n",
       "3  10    B    B    A    B    A    A    A    A    B   ...     0.440945   \n",
       "4  11    A    B    A    B    A    A    A    A    B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/test.csv.zip\n",
      "Dataset has 125546 samples with 131 features each.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125546 entries, 0 to 125545\n",
      "Columns: 131 entries, id to cont14\n",
      "dtypes: float64(14), int64(1), object(116)\n",
      "memory usage: 125.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9    ...        cont5  \\\n",
       "0   4    A    B    A    A    A    A    A    A    B    ...     0.281143   \n",
       "1   6    A    B    A    B    A    A    A    A    B    ...     0.836443   \n",
       "2   9    A    B    A    B    B    A    B    A    B    ...     0.718531   \n",
       "3  12    A    A    A    A    B    A    A    A    A    ...     0.397069   \n",
       "4  15    B    A    A    A    A    B    A    A    A    ...     0.302678   \n",
       "\n",
       "      cont6     cont7    cont8    cont9   cont10    cont11    cont12  \\\n",
       "0  0.466591  0.317681  0.61229  0.34365  0.38016  0.377724  0.369858   \n",
       "1  0.482425  0.443760  0.71330  0.51890  0.60401  0.689039  0.675759   \n",
       "2  0.212308  0.325779  0.29758  0.34365  0.30529  0.245410  0.241676   \n",
       "3  0.369930  0.342355  0.40028  0.33237  0.31480  0.348867  0.341872   \n",
       "4  0.398862  0.391833  0.23688  0.43731  0.50556  0.359572  0.352251   \n",
       "\n",
       "     cont13    cont14  \n",
       "0  0.704052  0.392562  \n",
       "1  0.453468  0.208045  \n",
       "2  0.258586  0.297232  \n",
       "3  0.592264  0.555955  \n",
       "4  0.301535  0.825823  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = loadData(datadir,'train.csv.zip')\n",
    "display(data.info())\n",
    "display(data.head(5))\n",
    "\n",
    "test_data= loadData(datadir,'test.csv.zip') \n",
    "display(test_data.info())\n",
    "display(test_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pre Proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data:', 188318)\n",
      "('test:', 125546)\n",
      "('combined:', 313864)\n",
      "Pre-Processing done\n",
      "('data:', 188318)\n",
      "('labels:', 188318)\n",
      "('test:', 125546)\n"
     ]
    }
   ],
   "source": [
    "# combine the two frames so we can encode the labels!\n",
    "test_data['loss']=0\n",
    "\n",
    "lengthofData=len(data)\n",
    "lengthoftest_data=len(test_data)\n",
    "\n",
    "print(\"data:\",lengthofData)\n",
    "print(\"test:\",lengthoftest_data)\n",
    "\n",
    "combineddata=pd.concat([data,test_data])\n",
    "lengthofcombined=len(combineddata)\n",
    "print(\"combined:\",lengthofcombined)\n",
    "\n",
    "# the categorical data that we need in a number format\n",
    "combineddata=LabelEncoder(combineddata)\n",
    "\n",
    "# time to split the data back apart!\n",
    "data=combineddata.iloc[:lengthofData].copy()\n",
    "test_data=combineddata.iloc[lengthofData:].copy()\n",
    "test_data.drop(['loss'],1,inplace=True) # didn't have this column before, make it go away!\n",
    "\n",
    "\n",
    "x_test = test_data.copy()\n",
    "x_test.drop(['id'],1,inplace=True)\n",
    "\n",
    "# we don't want the ID columns in X, and of course not loss either\n",
    "x=data.drop(['id','loss'],1)\n",
    "# loss is our label\n",
    "y=data['loss']\n",
    "\n",
    "#minmax scaler\n",
    "scaler= MinMaxScaler() \n",
    "x = scaler.fit_transform(x)\n",
    "x_test_data = scaler.fit_transform(x_test)\n",
    "\n",
    "#display(x[:5])\n",
    "#display(y.head(5))\n",
    "\n",
    "print(\"Pre-Processing done\")\n",
    "print(\"data:\",len(x))\n",
    "print(\"labels:\",len(y))\n",
    "print(\"test:\",len(x_test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking, Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of scikitlearn regressors to use:', 3)\n"
     ]
    }
   ],
   "source": [
    "# OK let's actually do some ML\n",
    "regrList=[] # a list of regressions to use\n",
    "#regrList.append(LinearRegression())\n",
    "regrList.append(ExtraTreesRegressor())\n",
    "regrList.append(Ridge())\n",
    "    \n",
    "regrList.append(RandomForestRegressor(n_estimators=10,\n",
    "                                      #criterion = 'mae',\n",
    "                                      n_jobs =-1, \n",
    "                                      random_state=42))\n",
    "print(\"number of scikitlearn regressors to use:\",len(regrList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into k-folds(divisions). train the regressors on each combination of k-1 folds, and then predict on the held-out fold. Preserve the prediction of each regressor for the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data: 188318\n",
      "folds at: [(0, 37663), (37663, 75326), (75326, 112989), (112989, 150652), (150652, 188318)]\n",
      "fold size: 37663\n",
      "train size: 150652\n",
      "188318\n"
     ]
    }
   ],
   "source": [
    "#prepare the fold divisions\n",
    "\n",
    "data_size=x.shape[0]\n",
    "print \"size of train data:\",data_size\n",
    "folds=[]\n",
    "num_folds=5\n",
    "fold_start=0\n",
    "for k in range(num_folds-1):\n",
    "    fold_end=((data_size/num_folds)*(k+1))\n",
    "    folds.append((fold_start,fold_end))\n",
    "    fold_start=fold_end\n",
    "folds.append((fold_start,data_size))\n",
    "print \"folds at:\",folds\n",
    "print \"fold size:\", (data_size/num_folds)\n",
    "print \"train size:\",(data_size/num_folds)*(num_folds-1)\n",
    "\n",
    "count=0\n",
    "for i in folds:\n",
    "    count+=i[1]-i[0]\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fold:', 0, 'to', 37663, 'of', 188318)\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "\n",
      "fit time:52.884s\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:0.498s\n",
      "Mean abs error: 1323.21\n",
      "Score: 0.47\n",
      "\n",
      "fit time:3.41s\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:0.013s\n",
      "Mean abs error: 1335.61\n",
      "Score: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:23: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:23.148s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "predict time:0.24s\n",
      "Mean abs error: 1328.68\n",
      "Score: 0.46\n",
      "[0]\ttrain-mae:2810.38+4.10425\ttest-mae:2810.39+13.8376\n",
      "[100]\ttrain-mae:1160.85+1.873\ttest-mae:1205.24+9.52449\n",
      "[200]\ttrain-mae:1120.23+2.3826\ttest-mae:1190.7+9.58269\n",
      "[300]\ttrain-mae:1094.37+2.77977\ttest-mae:1187.34+9.03897\n",
      "[400]\ttrain-mae:1071.08+2.74072\ttest-mae:1185.62+9.29755\n",
      "fit time:346.385s\n",
      "CV-Mean: 1185.5292665+9.33336483562\n",
      "Train time:108.527s\n",
      "XGB Mean abs error: 1191.07\n",
      "XGB predict time:0.358s\n",
      "--layer2 length: 37663\n",
      "--layer2 shape: (37663, 4)\n",
      "Fold run time:536.99s\n",
      "('Fold:', 37663, 'to', 75326, 'of', 188318)\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "\n",
      "fit time:52.666s\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:0.486s\n",
      "Mean abs error: 1308.89\n",
      "Score: 0.49\n",
      "\n",
      "fit time:3.73s\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:0.012s\n",
      "Mean abs error: 1322.17\n",
      "Score: 0.48\n",
      "\n",
      "fit time:23.667s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "predict time:0.215s\n",
      "Mean abs error: 1302.42\n",
      "Score: 0.49\n",
      "[0]\ttrain-mae:2809.09+4.38936\ttest-mae:2808.99+13.544\n",
      "[100]\ttrain-mae:1161.64+3.35354\ttest-mae:1207.56+8.07464\n",
      "[200]\ttrain-mae:1121.1+3.17341\ttest-mae:1192.8+8.28599\n",
      "[300]\ttrain-mae:1095.08+2.66846\ttest-mae:1189.66+8.56134\n",
      "[400]\ttrain-mae:1071.18+2.64621\ttest-mae:1187.87+9.04532\n",
      "fit time:427.849s\n",
      "CV-Mean: 1187.1240235+9.11880258704\n",
      "Train time:134.932s\n",
      "XGB Mean abs error: 1174.22\n",
      "XGB predict time:0.446s\n",
      "--layer2 length: 75326\n",
      "--layer2 shape: (75326, 4)\n",
      "Fold run time:645.448s\n",
      "('Fold:', 75326, 'to', 112989, 'of', 188318)\n",
      "\n",
      "folding! len test 37663, len train 150655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:44: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:55.463s\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:0.482s\n",
      "Mean abs error: 1325.54\n",
      "Score: 0.49\n",
      "\n",
      "fit time:3.596s\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:0.013s\n",
      "Mean abs error: 1330.79\n",
      "Score: 0.48\n",
      "\n",
      "fit time:23.837s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "predict time:0.222s\n",
      "Mean abs error: 1317.28\n",
      "Score: 0.48\n",
      "[0]\ttrain-mae:2806.92+1.9964\ttest-mae:2807.01+5.73712\n",
      "[100]\ttrain-mae:1158.66+2.67788\ttest-mae:1204.58+7.83471\n",
      "[200]\ttrain-mae:1118.97+2.40895\ttest-mae:1190.06+8.24861\n",
      "[300]\ttrain-mae:1092.67+2.31443\ttest-mae:1186.69+8.23425\n",
      "[400]\ttrain-mae:1069.29+2.70593\ttest-mae:1185.12+8.14569\n",
      "fit time:397.402s\n",
      "CV-Mean: 1184.49697875+8.26246020344\n",
      "Train time:125.146s\n",
      "XGB Mean abs error: 1183.30\n",
      "XGB predict time:0.432s\n",
      "--layer2 length: 112989\n",
      "--layer2 shape: (112989, 4)\n",
      "Fold run time:608.042s\n",
      "('Fold:', 112989, 'to', 150652, 'of', 188318)\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "\n",
      "fit time:52.748s\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:0.501s\n",
      "Mean abs error: 1326.89\n",
      "Score: 0.48\n",
      "\n",
      "fit time:3.63s\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:0.012s\n",
      "Mean abs error: 1338.83\n",
      "Score: 0.48\n",
      "\n",
      "fit time:22.549s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "predict time:0.233s\n",
      "Mean abs error: 1323.89\n",
      "Score: 0.49\n",
      "[0]\ttrain-mae:2808.43+3.51691\ttest-mae:2808.62+10.5181\n",
      "[100]\ttrain-mae:1160.1+1.84387\ttest-mae:1206.36+4.95637\n",
      "[200]\ttrain-mae:1120.01+1.1373\ttest-mae:1191.71+4.32804\n",
      "[300]\ttrain-mae:1093.27+1.03415\ttest-mae:1187.75+4.2928\n",
      "[400]\ttrain-mae:1069.19+1.2766\ttest-mae:1185.76+4.16066\n",
      "fit time:353.072s\n",
      "CV-Mean: 1185.69219975+4.13018238364\n",
      "Train time:111.198s\n",
      "XGB Mean abs error: 1187.97\n",
      "XGB predict time:0.374s\n",
      "--layer2 length: 150652\n",
      "--layer2 shape: (150652, 4)\n",
      "Fold run time:545.772s\n",
      "('Fold:', 150652, 'to', 188318, 'of', 188318)\n",
      "\n",
      "folding! len test 37666, len train 150652\n",
      "\n",
      "fit time:50.909s\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:0.487s\n",
      "Mean abs error: 1312.04\n",
      "Score: 0.49\n",
      "\n",
      "fit time:3.641s\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:0.012s\n",
      "Mean abs error: 1326.81\n",
      "Score: 0.48\n",
      "\n",
      "fit time:22.825s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "predict time:0.243s\n",
      "Mean abs error: 1311.63\n",
      "Score: 0.50\n",
      "[0]\ttrain-mae:2812.2+5.00212\ttest-mae:2812.21+15.5263\n",
      "[100]\ttrain-mae:1163.9+2.70454\ttest-mae:1209.32+6.98881\n",
      "[200]\ttrain-mae:1122.2+3.33957\ttest-mae:1193.98+7.17739\n",
      "[300]\ttrain-mae:1095.61+3.83574\ttest-mae:1190.43+7.38705\n",
      "[400]\ttrain-mae:1071.68+3.93111\ttest-mae:1188.53+7.73762\n",
      "fit time:423.796s\n",
      "CV-Mean: 1187.91854825+8.19098532301\n",
      "Train time:133.94s\n",
      "XGB Mean abs error: 1173.58\n",
      "XGB predict time:0.455s\n",
      "--layer2 length: 188318\n",
      "--layer2 shape: (188318, 4)\n",
      "Fold run time:637.729s\n",
      "Full run time:2973.982s\n"
     ]
    }
   ],
   "source": [
    "x_layer2=[]\n",
    "start_time0 = time.time()\n",
    "\n",
    "for fold_start,fold_end in folds:\n",
    "    print(\"Fold:\",fold_start,\"to\",fold_end,\"of\",data_size)\n",
    "    start_time1 = time.time()\n",
    "    fold_result=[]\n",
    "    \n",
    "    X_test = x[fold_start:fold_end].copy()\n",
    "    y_test = y[fold_start:fold_end].copy()\n",
    "    X_train=np.concatenate((x[:fold_start], x[fold_end:]), axis=0)\n",
    "    y_train=np.concatenate((y[:fold_start], y[fold_end:]), axis=0)\n",
    "    print \"\\nfolding! len test {}, len train {}\".format(len(X_test),len(X_train))\n",
    "    \n",
    "    for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
    "        start_time = time.time()\n",
    "        regrList[i].fit(X_train,y_train)\n",
    "        print(\"\\nfit time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(regrList[i])\n",
    "        curr_predict=regrList[i].predict(X_test)\n",
    "        if fold_result == []:\n",
    "            fold_result = np.array(curr_predict.copy())\n",
    "        else:\n",
    "            fold_result = np.column_stack((fold_result,curr_predict))\n",
    "        \n",
    "        print(\"predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "        #show some stats on that last regressions run    \n",
    "        print(\"Mean abs error: {:.2f}\".format(np.mean(abs(curr_predict - y_test))))\n",
    "        print(\"Score: {:.2f}\".format(regrList[i].score(X_test, y_test)))\n",
    "    \n",
    "    #XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    gbdt=xgbfit(X_train,y_train)\n",
    "\n",
    "    # now do a prediction and spit out a score(MAE) that means something\n",
    "    start_time = time.time()\n",
    "    curr_predict=gbdt.predict(dtest)\n",
    "    fold_result = np.column_stack((fold_result,curr_predict))  \n",
    "    print(\"XGB Mean abs error: {:.2f}\".format(np.mean(abs(curr_predict - y_test))))\n",
    "    print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    \n",
    "    if x_layer2 == []:\n",
    "        x_layer2=fold_result\n",
    "    else:\n",
    "        x_layer2=np.append(x_layer2,fold_result,axis=0)\n",
    "        \n",
    "    print \"--layer2 length:\",len(x_layer2)\n",
    "    print \"--layer2 shape:\",np.shape(x_layer2)\n",
    "    print(\"Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   \n",
    "print(\"Full run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### train layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188318\n",
      "188318\n",
      "Mean abs error: 1176.65\n",
      "Score: 0.57\n"
     ]
    }
   ],
   "source": [
    "print len(x_layer2)\n",
    "print len(y)\n",
    "\n",
    "#  train/validation split\n",
    "X_layer2_train, X_layer2_validation, y_layer2_train, y_layer2_validation = train_test_split( x_layer2,\n",
    "                                                                                y,\n",
    "                                                                                test_size=0.25,\n",
    "                                                                                random_state=42)\n",
    "layer2_regr=LinearRegression()\n",
    "\n",
    "layer2_regr.fit(X_layer2_train,y_layer2_train)\n",
    "\n",
    "layer2_predict=layer2_regr.predict(X_layer2_validation)\n",
    "\n",
    "#show some stats on that last regressions run    \n",
    "print(\"Mean abs error: {:.2f}\".format(np.mean(abs(layer2_predict - y_layer2_validation))))\n",
    "print(\"Score: {:.2f}\".format(layer2_regr.score(X_layer2_validation, y_layer2_validation)))\n",
    "\n",
    "\n",
    "#with LinearReg: Mean abs error: 1238.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188318\n",
      "188318\n",
      "[0]\ttrain-mae:2810.83+3.86743\ttest-mae:2810.79+11.7976\n",
      "fit time:6.485s\n",
      "CV-Mean: 1166.15332025+7.55760127596\n",
      "Train time:1.308s\n",
      "XGB Mean abs error: 1166.97\n",
      "XGB predict time:0.031s\n"
     ]
    }
   ],
   "source": [
    "# The XGB version of layer 2\n",
    "print len(x_layer2)\n",
    "print len(y)\n",
    "\n",
    "#  train/validation split\n",
    "X_layer2_train, X_layer2_validation, y_layer2_train, y_layer2_validation = train_test_split( x_layer2,\n",
    "                                                                                y,\n",
    "                                                                                test_size=0.25,\n",
    "                                                                                random_state=42)\n",
    "#XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "dtest = xgb.DMatrix(X_layer2_validation)\n",
    "layer2_gbdt=xgbfit(X_layer2_train,y_layer2_train)\n",
    "\n",
    "# now do a prediction and spit out a score(MAE) that means something\n",
    "start_time = time.time()\n",
    "print(\"XGB Mean abs error: {:.2f}\".format(np.mean(abs(layer2_gbdt.predict(dtest) - y_layer2_validation))))\n",
    "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "#with LinearReg: XGB Mean abs error: 1205.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict layer 1 on test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:1.887s\n",
      "[  2407.909   2239.736  10371.456 ...,   2240.309   1453.806   3673.435]\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:0.087s\n",
      "[  1155.44633825   1986.3797948   11490.70006385 ...,   2823.69355514\n",
      "   1076.85379674   4646.9250013 ]\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time:0.572s\n",
      "[ 2205.797  2107.822  8917.102 ...,  3224.901  1168.459  4035.305]\n",
      "XGB predict time:2.655s\n",
      "Fold run time:4.631s\n"
     ]
    }
   ],
   "source": [
    "x_layer2_test = []\n",
    "start_time1 = time.time()\n",
    "for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
    "    start_time = time.time()\n",
    "    print(regrList[i])\n",
    "    curr_predict=regrList[i].predict(x_test_data)\n",
    "    print(\"predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    \n",
    "    if x_layer2_test == []:\n",
    "        x_layer2_test = np.array(curr_predict.copy())\n",
    "    else:\n",
    "        x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
    "    print curr_predict\n",
    "\n",
    "#XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "dtest = xgb.DMatrix(x_test_data)\n",
    "# now do a prediction and spit out a score(MAE) that means something\n",
    "#start_time = time.time()\n",
    "curr_predict=gbdt.predict(dtest)\n",
    "x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
    "#print(\"Mean abs error: {:.2f}\".format(np.mean(abs(cache[i+1] - y_test))))\n",
    "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "print(\"Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'size of original test data:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "125546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(125546, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'train shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(188318, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sample of layer2 test:\\n', array([[  2407.909     ,   1155.44633825,   2205.797     ,   1731.03674316],\n",
      "       [  2239.736     ,   1986.3797948 ,   2107.822     ,   2027.17041016],\n",
      "       [ 10371.456     ,  11490.70006385,   8917.102     ,   9218.91113281],\n",
      "       [  5960.064     ,   5737.1042642 ,   4967.937     ,   6508.04541016]]))\n",
      "('x_layer2_test mean:', array([ 3101.97997922,  3056.02085022,  3087.85538827,  3031.2848828 ]))\n",
      "('x_layer2 mean:', array([ 3091.3479925 ,  3037.45612893,  3093.94178225,  3039.05493593]))\n",
      "('x_layer2_test std:', array([ 2234.92618833,  2016.1297939 ,  2242.43405966,  2186.0552338 ]))\n",
      "('x_layer2 std:', array([ 2269.34358108,  2017.89115492,  2266.12894136,  2228.9900701 ]))\n",
      "('num outliers:', 8)\n",
      "3091.3479925\n",
      "('num outliers:', 0)\n",
      "3091.3479925\n"
     ]
    }
   ],
   "source": [
    "# some problems noted---fact finding below!\n",
    "display(\"size of original test data:\",len(x_test_data))\n",
    "display(\"Test shape:\",np.shape(x_layer2_test))\n",
    "display(\"train shape:\",np.shape(x_layer2))\n",
    "\n",
    "print(\"sample of layer2 test:\\n\",x_layer2_test[:4])\n",
    "\n",
    "print(\"x_layer2_test mean:\",x_layer2_test.mean( axis=0))\n",
    "print(\"x_layer2 mean:\",x_layer2.mean(axis=0))\n",
    "train_layer2_col0_mean=x_layer2.mean(axis=0)[0]\n",
    "\n",
    "print(\"x_layer2_test std:\",x_layer2_test.std( axis=0)) \n",
    "print(\"x_layer2 std:\",x_layer2.std(axis=0))\n",
    "\n",
    "# notice that column 0(linregresion) has a significantly higher mean and std\n",
    "# here's a hack to not fix that for now! \n",
    "\n",
    "# check which row in column 0 are significantly far from the mean\n",
    "problem_column=x_layer2_test.T[0]\n",
    "outliers=[]\n",
    "for i in range(len(problem_column)):\n",
    "    if problem_column[i]>30000:\n",
    "        outliers.append((i,problem_column[i]))\n",
    "print(\"num outliers:\",len(outliers))\n",
    "\n",
    "#for each problem child, set them to the average value from the train set, to null the affect some\n",
    "for o in outliers:\n",
    "    problem_column[o[0]]=train_layer2_col0_mean\n",
    "    \n",
    "print(problem_column[o[0]])\n",
    "\n",
    "#check outliers again\n",
    "problem_column=x_layer2_test.T[0]\n",
    "outliers=[]\n",
    "for i in range(len(problem_column)):\n",
    "    if problem_column[i]>30000:\n",
    "        outliers.append((i,problem_column[i]))\n",
    "print(\"num outliers:\",len(outliers))\n",
    "\n",
    "print(x_layer2_test.T[0][o[0]]) # verify that the change made it all the way to the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1787.85220966\\n',\n",
       " '6,2033.11468598\\n',\n",
       " '9,9399.71331179\\n',\n",
       " '12,6416.62169659\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data['loss']=layer2_regr.predict(x_layer2_test)\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_stack.csv\"\n",
    "display(writeData(result,output_fname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1659.93640137\\n',\n",
       " '6,1838.11706543\\n',\n",
       " '9,9244.296875\\n',\n",
       " '12,5334.76025391\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the XGB version:\n",
    "\n",
    "dtest = xgb.DMatrix(x_layer2_test)\n",
    "test_data['loss']=layer2_gbdt.predict(dtest)\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_stack_xgb.csv\"\n",
    "display(writeData(result,output_fname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('result std:', id      170098.328125\n",
      "loss      1964.999512\n",
      "dtype: float32)\n"
     ]
    }
   ],
   "source": [
    "#let's have a look at the std of the result, as a cross check\n",
    "print(\"result std:\",result.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
